<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Test Webcam Emotion Detection</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }
    
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      min-height: 100vh;
      padding: 20px;
    }
    
    .container {
      max-width: 1200px;
      margin: 0 auto;
      background: white;
      border-radius: 20px;
      padding: 40px;
      box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
    }
    
    h1 {
      text-align: center;
      color: #333;
      margin-bottom: 30px;
    }
    
    .video-section {
      display: flex;
      gap: 30px;
      margin-bottom: 30px;
    }
    
    .video-container {
      flex: 1;
      position: relative;
      background: #000;
      border-radius: 15px;
      overflow: hidden;
    }
    
    video {
      width: 100%;
      height: auto;
      display: block;
    }
    
    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
    
    .emotion-overlay {
      position: absolute;
      bottom: 20px;
      left: 50%;
      transform: translateX(-50%);
      background: rgba(0, 0, 0, 0.9);
      color: white;
      padding: 15px 30px;
      border-radius: 30px;
      font-size: 24px;
      font-weight: bold;
      min-width: 250px;
      text-align: center;
    }
    
    .results-panel {
      flex: 1;
      background: #f5f5f5;
      border-radius: 15px;
      padding: 20px;
    }
    
    .emotion-bar {
      margin: 10px 0;
      background: white;
      border-radius: 8px;
      padding: 10px;
    }
    
    .emotion-label {
      display: flex;
      justify-content: space-between;
      margin-bottom: 5px;
      font-size: 14px;
    }
    
    .emotion-progress {
      height: 20px;
      background: #e0e0e0;
      border-radius: 10px;
      overflow: hidden;
    }
    
    .emotion-fill {
      height: 100%;
      background: linear-gradient(90deg, #667eea, #764ba2);
      transition: width 0.3s ease;
    }
    
    .controls {
      text-align: center;
      margin-bottom: 30px;
    }
    
    .btn {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
      border: none;
      padding: 15px 40px;
      border-radius: 30px;
      font-size: 16px;
      font-weight: 600;
      cursor: pointer;
      margin: 0 10px;
      transition: transform 0.2s;
    }
    
    .btn:hover {
      transform: translateY(-2px);
    }
    
    .btn:disabled {
      opacity: 0.5;
      cursor: not-allowed;
    }
    
    .status {
      text-align: center;
      padding: 15px;
      border-radius: 10px;
      margin-bottom: 20px;
      font-weight: 500;
    }
    
    .status.info { background: #e3f2fd; color: #1976d2; }
    .status.success { background: #e8f5e9; color: #388e3c; }
    .status.error { background: #ffebee; color: #d32f2f; }
    
    .instructions {
      background: #fff3cd;
      border: 2px solid #ffc107;
      border-radius: 10px;
      padding: 20px;
      margin-bottom: 20px;
    }
    
    .instructions h3 {
      margin-bottom: 10px;
      color: #856404;
    }
    
    .instructions ul {
      margin-left: 20px;
      color: #856404;
    }
    
    .instructions li {
      margin: 8px 0;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>üé≠ Real-Time Webcam Emotion Detection Test</h1>
    
    <div class="instructions">
      <h3>üìã Testing Instructions:</h3>
      <ul>
        <li><strong>Click "Start Camera"</strong> and allow camera access</li>
        <li><strong>Try different expressions:</strong> Happy (smile), Sad (frown), Angry (scowl), Surprised (wide eyes), Neutral (relaxed)</li>
        <li><strong>Watch the emotion bars</strong> update in real-time showing confidence levels</li>
        <li><strong>The dominant emotion</strong> will be displayed on the video overlay</li>
      </ul>
    </div>
    
    <div id="status" class="status info">
      Click "Start Camera" to begin emotion detection
    </div>
    
    <div class="controls">
      <button id="startBtn" class="btn">Start Camera</button>
      <button id="stopBtn" class="btn" disabled>Stop Camera</button>
    </div>
    
    <div class="video-section">
      <div class="video-container">
        <video id="webcam" autoplay playsinline></video>
        <canvas id="overlay"></canvas>
        <div class="emotion-overlay">
          <div id="emotionDisplay">üòê Waiting...</div>
        </div>
      </div>
      
      <div class="results-panel">
        <h3 style="margin-bottom: 15px;">üìä Emotion Confidence Levels</h3>
        
        <div class="emotion-bar">
          <div class="emotion-label">
            <span>üòä Happy</span>
            <span id="happy-percent">0%</span>
          </div>
          <div class="emotion-progress">
            <div id="happy-bar" class="emotion-fill" style="width: 0%"></div>
          </div>
        </div>
        
        <div class="emotion-bar">
          <div class="emotion-label">
            <span>üò¢ Sad</span>
            <span id="sad-percent">0%</span>
          </div>
          <div class="emotion-progress">
            <div id="sad-bar" class="emotion-fill" style="width: 0%"></div>
          </div>
        </div>
        
        <div class="emotion-bar">
          <div class="emotion-label">
            <span>üò† Angry</span>
            <span id="angry-percent">0%</span>
          </div>
          <div class="emotion-progress">
            <div id="angry-bar" class="emotion-fill" style="width: 0%"></div>
          </div>
        </div>
        
        <div class="emotion-bar">
          <div class="emotion-label">
            <span>üò≤ Surprised</span>
            <span id="surprised-percent">0%</span>
          </div>
          <div class="emotion-progress">
            <div id="surprised-bar" class="emotion-fill" style="width: 0%"></div>
          </div>
        </div>
        
        <div class="emotion-bar">
          <div class="emotion-label">
            <span>üòê Neutral</span>
            <span id="neutral-percent">0%</span>
          </div>
          <div class="emotion-progress">
            <div id="neutral-bar" class="emotion-fill" style="width: 0%"></div>
          </div>
        </div>
        
        <div class="emotion-bar">
          <div class="emotion-label">
            <span>üò® Fearful</span>
            <span id="fearful-percent">0%</span>
          </div>
          <div class="emotion-progress">
            <div id="fearful-bar" class="emotion-fill" style="width: 0%"></div>
          </div>
        </div>
        
        <div class="emotion-bar">
          <div class="emotion-label">
            <span>ü§¢ Disgusted</span>
            <span id="disgusted-percent">0%</span>
          </div>
          <div class="emotion-progress">
            <div id="disgusted-bar" class="emotion-fill" style="width: 0%"></div>
          </div>
        </div>
      </div>
    </div>
  </div>
  
  <!-- Load face-api.js from CDN -->
  <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.min.js"></script>
  
  <script>
    let stream = null;
    let detectionInterval = null;
    let modelsLoaded = false;
    
    const video = document.getElementById('webcam');
    const canvas = document.getElementById('overlay');
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const statusEl = document.getElementById('status');
    
    // Load face-api.js models
    async function loadModels() {
      if (modelsLoaded) return true;
      
      try {
        showStatus('Loading AI models for emotion detection...', 'info');
        
        const MODEL_URL = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model';
        
        await Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
          faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),
          faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL)
        ]);
        
        modelsLoaded = true;
        console.log('‚úÖ Models loaded successfully');
        return true;
        
      } catch (error) {
        console.error('‚ùå Error loading models:', error);
        showStatus('Error loading AI models: ' + error.message, 'error');
        return false;
      }
    }
    
    // Start camera
    startBtn.addEventListener('click', async () => {
      try {
        startBtn.disabled = true;
        
        // Load models first
        const loaded = await loadModels();
        if (!loaded) {
          startBtn.disabled = false;
          return;
        }
        
        showStatus('Requesting camera access...', 'info');
        
        // Get camera stream
        stream = await navigator.mediaDevices.getUserMedia({
          video: {
            width: { ideal: 640 },
            height: { ideal: 480 },
            facingMode: 'user'
          }
        });
        
        video.srcObject = stream;
        
        // Wait for video to be ready
        video.onloadedmetadata = () => {
          video.play();
          
          // Set canvas size to match video
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          
          showStatus('‚úÖ Camera active! Make different facial expressions to test.', 'success');
          
          stopBtn.disabled = false;
          
          // Start detection
          detectionInterval = setInterval(detectEmotion, 100); // 10 FPS
        };
        
      } catch (error) {
        console.error('Camera error:', error);
        showStatus('Camera access failed: ' + error.message, 'error');
        startBtn.disabled = false;
      }
    });
    
    // Stop camera
    stopBtn.addEventListener('click', () => {
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
        stream = null;
      }
      
      if (detectionInterval) {
        clearInterval(detectionInterval);
        detectionInterval = null;
      }
      
      video.srcObject = null;
      
      const ctx = canvas.getContext('2d');
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      
      startBtn.disabled = false;
      stopBtn.disabled = true;
      
      showStatus('Camera stopped', 'info');
      document.getElementById('emotionDisplay').textContent = 'üòê Stopped';
    });
    
    // Detect emotion
    async function detectEmotion() {
      if (!video || video.paused || video.ended || video.readyState < 2) {
        return;
      }
      
      try {
        // Detect face and expressions
        const detections = await faceapi
          .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions({
            inputSize: 224,
            scoreThreshold: 0.5
          }))
          .withFaceLandmarks()
          .withFaceExpressions();
        
        // Clear canvas
        const ctx = canvas.getContext('2d');
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        
        if (detections) {
          // Draw face detection box
          const box = detections.detection.box;
          ctx.strokeStyle = '#00ff00';
          ctx.lineWidth = 3;
          ctx.strokeRect(box.x, box.y, box.width, box.height);
          
          // Draw landmarks
          const landmarks = detections.landmarks.positions;
          ctx.fillStyle = '#00ff00';
          landmarks.forEach(point => {
            ctx.beginPath();
            ctx.arc(point.x, point.y, 2, 0, 2 * Math.PI);
            ctx.fill();
          });
          
          // Get expressions
          const expressions = detections.expressions;
          
          // Update emotion bars
          updateEmotionBar('happy', expressions.happy);
          updateEmotionBar('sad', expressions.sad);
          updateEmotionBar('angry', expressions.angry);
          updateEmotionBar('surprised', expressions.surprised);
          updateEmotionBar('neutral', expressions.neutral);
          updateEmotionBar('fearful', expressions.fearful);
          updateEmotionBar('disgusted', expressions.disgusted);
          
          // Find dominant emotion
          const emotionScores = {
            'Happy': expressions.happy,
            'Sad': expressions.sad,
            'Angry': expressions.angry,
            'Surprised': expressions.surprised,
            'Neutral': expressions.neutral,
            'Fearful': expressions.fearful,
            'Disgusted': expressions.disgusted
          };
          
          let dominantEmotion = 'Neutral';
          let maxConfidence = 0;
          
          for (const [emotion, confidence] of Object.entries(emotionScores)) {
            if (confidence > maxConfidence) {
              maxConfidence = confidence;
              dominantEmotion = emotion;
            }
          }
          
          const emojiMap = {
            'Happy': 'üòä',
            'Sad': 'üò¢',
            'Angry': 'üò†',
            'Surprised': 'üò≤',
            'Neutral': 'üòê',
            'Fearful': 'üò®',
            'Disgusted': 'ü§¢'
          };
          
          const emoji = emojiMap[dominantEmotion];
          const percent = Math.round(maxConfidence * 100);
          
          document.getElementById('emotionDisplay').textContent = 
            `${emoji} ${dominantEmotion} (${percent}%)`;
          
        } else {
          document.getElementById('emotionDisplay').textContent = 'üë§ No face detected';
          
          // Reset bars
          ['happy', 'sad', 'angry', 'surprised', 'neutral', 'fearful', 'disgusted'].forEach(emotion => {
            updateEmotionBar(emotion, 0);
          });
        }
        
      } catch (error) {
        console.error('Detection error:', error);
      }
    }
    
    function updateEmotionBar(emotion, confidence) {
      const percent = Math.round(confidence * 100);
      document.getElementById(`${emotion}-percent`).textContent = `${percent}%`;
      document.getElementById(`${emotion}-bar`).style.width = `${percent}%`;
    }
    
    function showStatus(message, type) {
      statusEl.textContent = message;
      statusEl.className = `status ${type}`;
    }
    
    // Cleanup on page unload
    window.addEventListener('beforeunload', () => {
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
      }
      if (detectionInterval) {
        clearInterval(detectionInterval);
      }
    });
  </script>
</body>
</html>
